[
  {
    "name": "Weinan Zhang",
    "publication_urls": [
      "https://arxiv.org/abs/2502.14361",
      "https://arxiv.org/abs/2502.13539",
      "https://arxiv.org/abs/2502.00510",
      "https://arxiv.org/abs/2502.13134",
      "https://arxiv.org/abs/2502.12492",
      "https://arxiv.org/abs/2501.18501",
      "https://arxiv.org/abs/2501.13344",
      "https://arxiv.org/abs/2412.18241",
      "https://openreview.net/forum?id=YXXmIHJQBN",
      "https://proceedings.neurips.cc/paper_files/paper/2024/hash/07e278a120830b10aae20cc600a8c07b-Abstract-Conference.html",
      "https://arxiv.org/abs/2409.17992"
    ],
    "summary": "The author's research spans a wide range of topics in artificial intelligence, focusing on enhancing the capabilities of large language models (LLMs) and addressing key challenges in various applications. Here are the main research contributions:\n\n1. **Mathematical Reasoning and Generalization**:\n   - Developed **Retrieval-Augmented Process Reward Model (RetrievalPRM)** to improve the generalization of process reward models in mathematical reasoning tasks. This framework addresses out-of-distribution (OOD) issues by using a retrieval-enhanced mechanism to find semantically similar questions and steps, thereby enhancing the model's ability to evaluate reasoning steps and improving consistency across different models and problem types.\n\n2. **Recommender Systems and Serendipity**:\n   - Introduced **SERAL (Serendipity Recommendations with Aligned Large Language Models)**, a framework that enhances serendipity recommendations in recommender systems. SERAL addresses the filter bubble effect by aligning serendipity judgments with human preferences and integrating efficiently into industrial pipelines, leading to improved user satisfaction and engagement.\n\n3. **Modular Attribution in LLM Agents**:\n   - Proposed **CapaBench**, a game-theoretic evaluation benchmark for modular attribution in LLM agents. CapaBench uses Shapley Values to measure the contributions of individual modules and their interactions, providing a principled method for optimizing and interpreting modular LLM agents in complex tasks.\n\n4. **Human-Robot Interaction**:\n   - Developed **RHINO (Real-time Humanoid-human Interaction and Object manipulation)**, a framework that enables humanoid robots to perform real-time reactions and manipulations based on human instructions and interaction signals. RHINO decouples the interaction process into high-level planning and low-level control, enhancing the robot's adaptability and safety in dynamic environments.\n\n5. **Code Generation and System2-to-System1 Methods**:\n   - Presented the **BDC (Boost, Disentangle, and Customize) framework** for code generation, which explores System 2 reasoning knowledge of LLMs using a Monte-Carlo Tree Search process and disentangles heterogeneous data for composable LoRA-experts. This framework offers a robust and flexible solution for generating customized problem solvers.\n\n6. **Particle Filtering and State Estimation**:\n   - Introduced the **Diffusion-Enhanced Particle Filtering Framework** to address the Prior Boundary Phenomenon in particle filtering. This framework includes adaptive diffusion, entropy-driven regularization, and kernel-based perturbations to ensure robust state estimation for out-of-boundary targets, significantly improving success rates and estimation accuracy.\n\n7. **Sequential Behavior Comprehension in Recommendation**:\n   - Proposed **ReLLaX (Retrieval-enhanced Large Language models Plus)**, a framework that optimizes LLMs for recommendation by reducing sequence heterogeneity, injecting collaborative knowledge, and enhancing parameter interactions. ReLLaX effectively mitigates the lifelong sequential behavior incomprehension problem and improves recommendation performance.\n\n8. **Graph Construction for Recommendation**:\n   - Developed **AutoGraph**, an automatic graph construction framework based on LLMs for recommendation. AutoGraph infers user preferences and item knowledge, incorporates latent factors, and uses metapath-based message aggregation to create graphs with in-depth global-view semantics, enhancing recommendation accuracy and efficiency.\n\n9. **Predictive Modeling on Relational Databases**:\n   - Created **4DBInfer**, a 4D benchmarking toolbox for graph-centric predictive modeling on relational databases (RDBs). 4DBInfer addresses the lack of suitable benchmarks by assembling large-scale RDB datasets and predictive tasks, providing a unified and scalable open-source tool for training and evaluation.\n\n10. **Multi-Agent Learning with Diffusion Models**:\n    - Introduced **MADiff**, the first diffusion-based multi-agent learning framework. MADiff uses an attention-based diffusion model to model complex coordination among multiple agents, outperforming baseline algorithms in various multi-agent learning tasks.\n\n11. **Lifelong Policy Adaptation for Legged Robots**:\n    - Developed **LoopSR**, a lifelong policy adaptation framework for legged robots. LoopSR uses a transformer-based encoder to project real-world trajectories into a latent space and reconstruct real-world environments in simulation for further training, achieving superior data efficiency and performance in both simulated and real-world experiments.\n\nThese contributions collectively advance the state-of-the-art in AI, particularly in areas such as mathematical reasoning, recommendation systems, human-robot interaction, code generation, state estimation, and multi-agent learning.",
    "list_of_pubs": [
      {
        "title": "Retrieval-Augmented Process Reward Model for Generalizable Mathematical Reasoning",
        "abstract": "While large language models (LLMs) have significantly advanced mathematical reasoning, Process Reward Models (PRMs) have been developed to evaluate the logical validity of reasoning steps. However, PRMs still struggle with out-of-distribution (OOD) challenges. This paper identifies key OOD issues, including step OOD, caused by differences in reasoning patterns across model types and sizes, and question OOD, which arises from dataset shifts between training data and real-world problems. To address these issues, we introduce Retrieval-Augmented Process Reward Model (RetrievalPRM), a novel framework designed to tackle these OOD issues. By utilizing a two-stage retrieval-enhanced mechanism, RetrievalPRM retrieves semantically similar questions and steps as a warmup, enhancing PRM's ability to evaluate target steps and improving generalization and reasoning consistency across different models and problem types. Our extensive experiments demonstrate that RetrievalPRM outperforms existing baselines across multiple real-world datasets. Our open-source contributions include a retrieval-enhanced dataset, a tuning framework for PRM training, and the RetrievalPRM model, establishing a new standard for PRM performance."
      },
      {
        "title": "Bursting Filter Bubble: Enhancing Serendipity Recommendations with Aligned Large Language Models",
        "abstract": "Recommender systems (RSs) often suffer from the feedback loop phenomenon, e.g., RSs are trained on data biased by their recommendations. This leads to the filter bubble effect that reinforces homogeneous content and reduces user satisfaction. To this end, serendipity recommendations, which offer unexpected yet relevant items, are proposed. Recently, large language models (LLMs) have shown potential in serendipity prediction due to their extensive world knowledge and reasoning capabilities. However, they still face challenges in aligning serendipity judgments with human assessments, handling long user behavior sequences, and meeting the latency requirements of industrial RSs. To address these issues, we propose SERAL (Serendipity Recommendations with Aligned Large Language Models), a framework comprising three stages: (1) Cognition Profile Generation to compress user behavior into multi-level profiles; (2) SerenGPT Alignment to align serendipity judgments with human preferences using enriched training data; and (3) Nearline Adaptation to integrate SerenGPT into industrial RSs pipelines efficiently. Online experiments demonstrate that SERAL improves exposure ratio (PVR), clicks, and transactions of serendipitous items by 5.7%, 29.56%, and 27.6%, enhancing user experience without much impact on overall revenue. Now, it has been fully deployed in the \"Guess What You Like\" of the Taobao App homepage."
      },
      {
        "title": "Who's the MVP? A Game-Theoretic Evaluation Benchmark for Modular Attribution in LLM Agents",
        "abstract": "Large Language Model (LLM) agents frameworks often employ modular architectures, incorporating components such as planning, reasoning, action execution, and reflection to tackle complex tasks. However, quantifying the contribution of each module to overall system performance remains a significant challenge, impeding optimization and interpretability. To address this, we introduce CapaBench (Capability-level Assessment Benchmark), an evaluation framework grounded in cooperative game theory's Shapley Value, which systematically measures the marginal impact of individual modules and their interactions within an agent's architecture. By replacing default modules with test variants across all possible combinations, CapaBench provides a principle method for attributing performance contributions. Key contributions include: (1) We are the first to propose a Shapley Value-based methodology for quantifying the contributions of capabilities in LLM agents; (2) Modules with high Shapley Values consistently lead to predictable performance gains when combined, enabling targeted optimization; and (3) We build a multi-round dataset of over 1,500 entries spanning diverse domains and practical task scenarios, enabling comprehensive evaluation of agent capabilities. CapaBench bridges the gap between component-level evaluation and holistic system assessment, providing actionable insights for optimizing modular LLM agents and advancing their deployment in complex, real-world scenarios."
      },
      {
        "title": "RHINO: Learning Real-Time Humanoid-Human-Object Interaction from Human Demonstrations",
        "abstract": "Humanoid robots have shown success in locomotion and manipulation. Despite these basic abilities, humanoids are still required to quickly understand human instructions and react based on human interaction signals to become valuable assistants in human daily life. Unfortunately, most existing works only focus on multi-stage interactions, treating each task separately, and neglecting real-time feedback. In this work, we aim to empower humanoid robots with real-time reaction abilities to achieve various tasks, allowing human to interrupt robots at any time, and making robots respond to humans immediately. To support such abilities, we propose a general humanoid-human-object interaction framework, named RHINO, i.e., Real-time Humanoid-human Interaction and Object manipulation. RHINO provides a unified view of reactive motion, instruction-based manipulation, and safety concerns, over multiple human signal modalities, such as languages, images, and motions. RHINO is a hierarchical learning framework, enabling humanoids to learn reaction skills from human-human-object demonstrations and teleoperation data. In particular, it decouples the interaction process into two levels: 1) a high-level planner inferring human intentions from real-time human behaviors; and 2) a low-level controller achieving reactive motion behaviors and object manipulation skills based on the predicted intentions. We evaluate the proposed framework on a real humanoid robot and demonstrate its effectiveness, flexibility, and safety in various scenarios."
      },
      {
        "title": "Boost, Disentangle, and Customize: A Robust System2-to-System1 Pipeline for Code Generation",
        "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in various domains, particularly in system 1 tasks, yet the intricacies of their problem-solving mechanisms in system 2 tasks are not sufficiently explored. Recent research on System2-to-System1 methods surge, exploring the System 2 reasoning knowledge via inference-time computation and compressing the explored knowledge into System 1 process. In this paper, we focus on code generation, which is a representative System 2 task, and identify two primary challenges: (1) the complex hidden reasoning processes and (2) the heterogeneous data distributions that complicate the exploration and training of robust LLM solvers. To tackle these issues, we propose a novel BDC framework that explores insightful System 2 knowledge of LLMs using a MC-Tree-Of-Agents algorithm with mutual \\textbf{B}oosting, \\textbf{D}isentangles the heterogeneous training data for composable LoRA-experts, and obtain \\textbf{C}ustomized problem solver for each data instance with an input-aware hypernetwork to weight over the LoRA-experts, offering effectiveness, flexibility, and robustness. This framework leverages multiple LLMs through mutual verification and boosting, integrated into a Monte-Carlo Tree Search process enhanced by reflection-based pruning and refinement. Additionally, we introduce the DisenLora algorithm, which clusters heterogeneous data to fine-tune LLMs into composable Lora experts, enabling the adaptive generation of customized problem solvers through an input-aware hypernetwork. This work lays the groundwork for advancing LLM capabilities in complex reasoning tasks, offering a novel System2-to-System1 solution."
      },
      {
        "title": "Beyond Prior Limits: Addressing Distribution Misalignment in Particle Filtering",
        "abstract": "Particle filtering is a Bayesian inference method and a fundamental tool in state estimation for dynamic systems, but its effectiveness is often limited by the constraints of the initial prior distribution, a phenomenon we define as the Prior Boundary Phenomenon. This challenge arises when target states lie outside the prior's support, rendering traditional particle filtering methods inadequate for accurate estimation. Although techniques like unbounded priors and larger particle sets have been proposed, they remain computationally prohibitive and lack adaptability in dynamic scenarios. To systematically overcome these limitations, we propose the Diffusion-Enhanced Particle Filtering Framework, which introduces three key innovations: adaptive diffusion through exploratory particles, entropy-driven regularisation to prevent weight collapse, and kernel-based perturbations for dynamic support expansion. These mechanisms collectively enable particle filtering to explore beyond prior boundaries, ensuring robust state estimation for out-of-boundary targets. Theoretical analysis and extensive experiments validate framework's effectiveness, indicating significant improvements in success rates and estimation accuracy across high-dimensional and non-convex scenarios."
      },
      {
        "title": "Full-Stack Optimized Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation",
        "abstract": "In this paper, we address the lifelong sequential behavior incomprehension problem in large language models (LLMs) for recommendation, where LLMs struggle to extract useful information from long user behavior sequences, even within their context limits. To tackle this, we propose ReLLaX (Retrieval-enhanced Large Language models Plus), a framework offering optimization across data, prompt, and parameter levels. At the data level, we introduce Semantic User Behavior Retrieval (SUBR) to reduce sequence heterogeneity, making it easier for LLMs to extract key information. For prompt-level enhancement, we employ Soft Prompt Augmentation (SPA) to inject collaborative knowledge, aligning item representations with recommendation tasks and improving LLMs's exploration of item relationships. Finally, at the parameter level, we propose Component Fully-interactive LoRA (CFLoRA), which enhances LoRA's expressiveness by enabling interactions between its components, allowing better capture of sequential information. Moreover, we present new perspectives to compare current LoRA-based LLM4Rec methods, i.e. from both a composite and a decomposed view. We theoretically demonstrate that the ways they employ LoRA for recommendation are degraded versions of our CFLoRA, with different constraints on atom component interactions. Extensive experiments on three public datasets demonstrate ReLLaX's superiority over existing baselines and its ability to mitigate lifelong sequential behavior incomprehension effectively."
      },
      {
        "title": "An Automatic Graph Construction Framework based on Large Language Models for Recommendation",
        "abstract": "Graph neural networks (GNNs) have emerged as state-of-the-art methods to learn from graph-structured data for recommendation. However, most existing GNN-based recommendation methods focus on the optimization of model structures and learning strategies based on pre-defined graphs, neglecting the importance of the graph construction stage. Earlier works for graph construction usually rely on speciffic rules or crowdsourcing, which are either too simplistic or too labor-intensive. Recent works start to utilize large language models (LLMs) to automate the graph construction, in view of their abundant open-world knowledge and remarkable reasoning capabilities. Nevertheless, they generally suffer from two limitations: (1) invisibility of global view (e.g., overlooking contextual information) and (2) construction inefficiency. To this end, we introduce AutoGraph, an automatic graph construction framework based on LLMs for recommendation. Specifically, we first use LLMs to infer the user preference and item knowledge, which is encoded as semantic vectors. Next, we employ vector quantization to extract the latent factors from the semantic vectors. The latent factors are then incorporated as extra nodes to link the user/item nodes, resulting in a graph with in-depth global-view semantics. We further design metapath-based message aggregation to effectively aggregate the semantic and collaborative information. The framework is model-agnostic and compatible with different backbone models. Extensive experiments on three real-world datasets demonstrate the efficacy and efffciency of AutoGraph compared to existing baseline methods. We have deployed AutoGraph in Huawei advertising platform, and gain a 2.69% improvement on RPM and a 7.31% improvement on eCPM in the online A/B test. Currently AutoGraph has been used as the main trafffc model, serving hundreds of millions of people."
      },
      {
        "title": "4DBInfer: A 4D Benchmarking Toolbox for Graph-Centric Predictive Modeling on RDBs",
        "abstract": "Given a relational database (RDB), how can we predict missing column values in some target table of interest? Although RDBs store vast amounts of rich, informative data spread across interconnected tables, the progress of predictive machine learning models as applied to such tasks arguably falls well behind advances in other domains such as computer vision or natural language processing. This deficit stems, at least in part, from the lack of established/public RDB benchmarks as needed for training and evaluation purposes. As a result, related model development thus far often defaults to tabular approaches trained on ubiquitous single-table benchmarks, or on the relational side, graph-based alternatives such as GNNs applied to a completely different set of graph datasets devoid of tabular characteristics. To more precisely target RDBs lying at the nexus of these two complementary regimes, we explore a broad class of baseline models predicated on: (i) converting multi-table datasets into graphs using various strategies equipped with efficient subsampling, while preserving tabular characteristics; and (ii) trainable models with well-matched inductive biases that output predictions based on these input subgraphs. Then, to address the dearth of suitable public benchmarks and reduce siloed comparisons, we assemble a diverse collection of (i) large-scale RDB datasets and (ii) coincident predictive tasks. From a delivery standpoint, we operationalize the above four dimensions (4D) of exploration within a unified, scalable open-source toolbox called 4DBInfer; please see https://github.com/awslabs/multi-table-benchmark ."
      },
      {
        "title": "MADiff: Offline Multi-agent Learning with Diffusion Models",
        "abstract": "Offline reinforcement learning (RL) aims to learn policies from pre-existing datasets without further interactions, making it a challenging task. Q-learning algorithms struggle with extrapolation errors in offline settings, while supervised learning methods are constrained by model expressiveness. Recently, diffusion models (DMs) have shown promise in overcoming these limitations in single-agent learning, but their application in multi-agent scenarios remains unclear. Generating trajectories for each agent with independent DMs may impede coordination, while concatenating all agents\u2019 information can lead to low sample efficiency. Accordingly, we propose MADiff, which is realized with an attention-based diffusion model to model the complex coordination among behaviors of multiple agents. To our knowledge, MADiff is the first diffusion-based multi-agent learning framework, functioning as both a decentralized policy and a centralized controller. During decentralized executions, MADiff simultaneously performs teammate modeling, and the centralized controller can also be applied in multi-agent trajectory predictions. Our experiments demonstrate that MADiff outperforms baseline algorithms across various multi-agent learning tasks, highlighting its effectiveness in modeling complex multi-agent interactions."
      },
      {
        "title": "LoopSR: Looping Sim-and-Real for Lifelong Policy Adaptation of Legged Robots",
        "abstract": "Reinforcement Learning (RL) has shown its remarkable and generalizable capability in legged locomotion through sim-to-real transfer. However, while adaptive methods like domain randomization are expected to make policy more robust to diverse environments, such comprehensiveness potentially detracts from the policy's performance in any specific environment according to the No Free Lunch theorem, leading to a suboptimal solution once deployed in the real world. To address this issue, we propose a lifelong policy adaptation framework named LoopSR, which utilizes a transformer-based encoder to project real-world trajectories into a latent space, and accordingly reconstruct the real-world environments back in simulation for further improvement. Autoencoder architecture and contrastive learning methods are adopted to better extract the characteristics of real-world dynamics. The simulation parameters for continual training are derived by combining predicted parameters from the decoder with retrieved parameters from the simulation trajectory dataset. By leveraging the continual training, LoopSR achieves superior data efficiency compared with strong baselines, with only a limited amount of data to yield eminent performance in both sim-to-sim and sim-to-real experiments."
      }
    ]
  },
  {
    "name": "Wenyue Hua",
    "publication_urls": [
      "https://arxiv.org/abs/2502.11436",
      "https://arxiv.org/abs/2502.13160",
      "https://arxiv.org/abs/2412.08972",
      "https://arxiv.org/abs/2411.13504",
      "https://openreview.net/forum?id=BwR8t91yqh",
      "https://arxiv.org/abs/2403.16971"
    ],
    "summary": "The author's research contributions span multiple dimensions of Large Language Model (LLM) technology, focusing on enhancing the performance, efficiency, and applicability of LLMs in various contexts. Here are the key areas of contribution:\n\n1. **Input Data Optimization for LLMs**:\n   - Developed a novel approach called ADO (Automatic Data Optimization) to optimize input data within LLM prompts.\n   - Introduced techniques such as content engineering (imputing missing values, removing irrelevant attributes, and enriching profiles) and structural reformulation to improve the presentation of input data.\n   - Demonstrated significant performance improvements in LLMs across various tasks, highlighting the importance of input data quality in prompt engineering.\n\n2. **Dynamic Information Diffusion in Multi-Agent Systems**:\n   - Studied the dynamics of information diffusion in multi-agent systems using LLMs, particularly in environments characterized by information asymmetry.\n   - Designed a dynamic attention mechanism to help agents better allocate attention to different information sources.\n   - Observed the emergence of phenomena like information cocoons, the evolution of information gaps, and the accumulation of social capital, linking these to psychological, sociological, and communication theories.\n\n3. **Rule-Guided Reasoning Benchmark**:\n   - Created RuleArena, a benchmark for evaluating LLMs' ability to follow complex, real-world rules in reasoning.\n   - Covered practical domains such as airline baggage fees, NBA transactions, and tax regulations, assessing LLMs' proficiency in long-context understanding, logical reasoning, and accurate mathematical computation.\n   - Identified significant limitations in LLMs, including difficulties in identifying and applying the correct rules and performing accurate calculations.\n\n4. **Memory and Reasoning Decomposition in LLMs**:\n   - Proposed a new inference paradigm that separates the LLM inference process into distinct memory recall and reasoning steps.\n   - Introduced special tokens to guide the model in distinguishing between knowledge retrieval and reasoning actions.\n   - Enhanced model performance and interpretability, reducing issues such as hallucinations and knowledge forgetting.\n\n5. **Interactive Speculative Planning for Agent Efficiency**:\n   - Developed a human-centered efficient agent planning method called Interactive Speculative Planning to enhance the efficiency of LLM-based agents.\n   - Advocated for the co-design of the agent system and user interface, emphasizing the importance of managing user interactions and interruptions.\n   - Improved the overall planning efficiency by leveraging human-in-the-loop interactions to provide accurate intermediate steps.\n\n6. **AIOS: LLM Agent Operating System**:\n   - Proposed AIOS, an operating system for managing LLM-based agents, addressing resource management challenges.\n   - Designed an architecture that isolates resources and LLM-specific services into an AIOS kernel, providing fundamental services such as scheduling, context management, and memory management.\n   - Demonstrated significant performance improvements in agent execution, achieving up to 2.1x faster execution times for various agent frameworks.\n\nOverall, the author's research contributes to advancing the state-of-the-art in LLM technology by addressing critical issues in input data optimization, information diffusion, rule-guided reasoning, memory and reasoning decomposition, agent efficiency, and resource management. These contributions have the potential to significantly enhance the reliability, efficiency, and applicability of LLMs in real-world scenarios.",
    "list_of_pubs": [
      {
        "title": "ADO: Automatic Data Optimization for Inputs in LLM Prompts",
        "abstract": "This study explores a novel approach to enhance the performance of Large Language Models (LLMs) through the optimization of input data within prompts. While previous research has primarily focused on refining instruction components and augmenting input data with in-context examples, our work investigates the potential benefits of optimizing the input data itself. We introduce a two-pronged strategy for input data optimization: content engineering and structural reformulation. Content engineering involves imputing missing values, removing irrelevant attributes, and enriching profiles by generating additional information inferred from existing attributes. Subsequent to content engineering, structural reformulation is applied to optimize the presentation of the modified content to LLMs, given their sensitivity to input format. Our findings suggest that these optimizations can significantly improve the performance of LLMs in various tasks, offering a promising avenue for future research in prompt engineering. The source code is available at https://anonymous.4open.science/r/ADO-6BC5/"
      },
      {
        "title": "Understanding Dynamic Diffusion Process of LLM-based Agents under Information Asymmetry",
        "abstract": "Large language models have been used to simulate human society using multi-agent systems. Most current social simulation research emphasizes interactive behaviors in fixed environments, ignoring information opacity, relationship variability and diffusion diversity. In this paper, we study the dynamics of information diffusion in 12 asymmetric open environments defined by information content and distribution mechanisms. We first present a general framework to capture the features of information diffusion. Then, we designed a dynamic attention mechanism to help agents allocate attention to different information, addressing the limitations of LLM-based attention. Agents start by responding to external information stimuli within a five-agent group, increasing group size and forming information circles while developing relationships and sharing information. Additionally, we observe the emergence of information cocoons, the evolution of information gaps, and the accumulation of social capital, which are closely linked to psychological, sociological, and communication theories."
      },
      {
        "title": "RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios",
        "abstract": "This paper introduces RuleArena, a novel and challenging benchmark designed to evaluate the ability of large language models (LLMs) to follow complex, real-world rules in reasoning. Covering three practical domains -- airline baggage fees, NBA transactions, and tax regulations -- RuleArena assesses LLMs' proficiency in handling intricate natural language instructions that demand long-context understanding, logical reasoning, and accurate mathematical computation. Two key attributes distinguish RuleArena from traditional rule-based reasoning benchmarks: (1) it extends beyond standard first-order logic representations, and (2) it is grounded in authentic, practical scenarios, providing insights into the suitability and reliability of LLMs for real-world applications. Our findings reveal several notable limitations in LLMs: (1) they struggle to identify and apply the appropriate rules, frequently becoming confused by similar but distinct regulations, (2) they cannot consistently perform accurate mathematical computations, even when they correctly identify the relevant rules, and (3) in general, they perform poorly in the benchmark. These results highlight significant challenges in advancing LLMs' rule-guided reasoning capabilities in real-life applications."
      },
      {
        "title": "Disentangling Memory and Reasoning Ability in Large Language Models",
        "abstract": "Large Language Models (LLMs) have demonstrated strong performance in handling complex tasks requiring both extensive knowledge and reasoning abilities. However, the existing LLM inference pipeline operates as an opaque process without explicit separation between knowledge retrieval and reasoning steps, making the model's decision-making process unclear and disorganized. This ambiguity can lead to issues such as hallucinations and knowledge forgetting, which significantly impact the reliability of LLMs in high-stakes domains. In this paper, we propose a new inference paradigm that decomposes the complex inference process into two distinct and clear actions: (1) memory recall: which retrieves relevant knowledge, and (2) reasoning: which performs logical steps based on the recalled knowledge. To facilitate this decomposition, we introduce two special tokens memory and reason, guiding the model to distinguish between steps that require knowledge retrieval and those that involve reasoning. Our experiment results show that this decomposition not only improves model performance but also enhances the interpretability of the inference process, enabling users to identify sources of error and refine model responses effectively. The code is available at https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning."
      },
      {
        "title": "Interactive Speculative Planning: Enhance Agent Efficiency through Co-design of System and User Interface",
        "abstract": "Agents, as user-centric tools, are increasingly deployed for human task delegation, assisting with a broad spectrum of requests by generating thoughts, engaging with user proxies, and producing action plans. However, agents based on large language models often face substantial planning latency due to two primary factors: the efficiency limitations of the underlying LLMs due to their large size and high demand, and the structural complexity of the agents due to the extensive generation of intermediate steps to produce the final output. Given that inefficiency in service provision can undermine the value of automation for users, this paper presents a human-centered efficient agent planning method \u2013 Interactive Speculative Planning \u2013 aiming at enhancing the efficiency of agent planning through both system design and user interaction. Our approach advocates for the co-design of the agent system and user interface, underscoring the importance of an agent system that can fluidly manage user interactions and interruptions. By integrating human interruptions as a fundamental component of the system, we not only make it more user-centric but also expedite the entire process by leveraging human-in-the-loop interactions to provide accurate intermediate steps."
      },
      {
        "title": "AIOS: LLM Agent Operating System",
        "abstract": "LLM-based intelligent agents face significant deployment challenges, particularly related to resource management. Allowing unrestricted access to LLM or tool resources can lead to inefficient or even potentially harmful resource allocation and utilization for agents. Furthermore, the absence of proper scheduling and resource management mechanisms in current agent designs hinders concurrent processing and limits overall system efficiency. As the diversity and complexity of agents continue to grow, addressing these resource management issues becomes increasingly critical to LLM-based agent systems. To address these challenges, this paper proposes the architecture of AIOS (LLM-based AI Agent Operating System) under the context of managing LLM-based agents. It introduces a novel architecture for serving LLM-based agents by isolating resources and LLM-specific services from agent applications into an AIOS kernel. This AIOS kernel provides fundamental services (e.g., scheduling, context management, memory management, storage management, access control) and efficient management of resources (e.g., LLM and external tools) for runtime agents. To enhance usability, AIOS also includes an AIOS-Agent SDK, a comprehensive suite of APIs designed for utilizing functionalities provided by the AIOS kernel. Experimental results demonstrate that using AIOS can achieve up to 2.1x faster execution for serving agents built by various agent frameworks. The source code is available at https://github.com/agiresearch/AIOS."
      }
    ]
  },
  {
    "name": "Minghuan Liu",
    "publication_urls": [
      "https://arxiv.org/abs/2502.08645",
      "https://arxiv.org/abs/2412.14058",
      "https://arxiv.org/abs/2410.03645",
      "https://arxiv.org/abs/2405.19189",
      "https://proceedings.neurips.cc/paper_files/paper/2024/hash/07e278a120830b10aae20cc600a8c07b-Abstract-Conference.html",
      "https://openreview.net/forum?id=OnM3R47KIiU"
    ],
    "summary": "The author's research contributions span several key areas in robotics and machine learning, particularly focusing on improving the scalability, realism, and generalizability of robotic systems through advanced simulation techniques, multi-modal learning, and reinforcement learning. Here are the main contributions:\n\n1. **High-Fidelity Simulation for Robotic Manipulation**:\n   - Developed **RE\u00b3SIM**, a 3D-photorealistic real-to-sim system that addresses geometric and visual sim-to-real gaps.\n   - Utilizes advanced 3D reconstruction and neural rendering to create realistic simulations, enabling efficient data collection and training of robot policies.\n   - Achieves zero-shot sim-to-real transfer with high success rates, demonstrating the system's effectiveness in various manipulation tasks.\n\n2. **Vision-Language-Action (VLA) Models for Generalist Robot Policies**:\n   - Conducted a comprehensive study on the key factors influencing the performance of VLA models, which integrate vision, language, and action.\n   - Introduced **RoboVLMs**, a new family of VLA models that require minimal manual design and achieve state-of-the-art performance in both simulation and real-world tasks.\n   - Provided a detailed guidebook and open-source framework to facilitate future research and development in VLA models.\n\n3. **Scalable Data Generation for Robotics**:\n   - Proposed **GenSim2**, a framework that leverages multi-modal and reasoning language models (LLMs) to automatically generate diverse and realistic simulation tasks and scenes.\n   - Developed an effective multi-task language-conditioned policy architecture, **PPT (Proprioceptive Point-Cloud Transformer)**, that learns from generated demonstrations and shows strong sim-to-real zero-shot transfer.\n   - Demonstrated significant improvements in policy performance by combining generated data with real-world data.\n\n4. **Long-Horizon Rollout with Dynamics Diffusion**:\n   - Explored the use of diffusion models (DMs) for long-horizon rollouts in offline reinforcement learning.\n   - Introduced **DyDiff (Dynamics Diffusion)**, a method that injects information from the learning policy into DMs iteratively, ensuring accurate and consistent long-horizon rollouts.\n   - Provided theoretical analysis and empirical validation of DyDiff's effectiveness in offline reinforcement learning settings.\n\n5. **Multi-Agent Learning with Diffusion Models**:\n   - Addressed the challenge of applying diffusion models to multi-agent scenarios, proposing **MADiff**.\n   - Utilized an attention-based diffusion model to model complex coordination among multiple agents, functioning as both a decentralized policy and a centralized controller.\n   - Demonstrated superior performance of MADiff in various multi-agent learning tasks, highlighting its capability in modeling complex interactions.\n\n6. **Visual Imitation Learning with Patch Rewards**:\n   - Developed **PatchAIL**, a method that measures the expertise of local image regions (patches) and recovers multi-dimensional patch rewards.\n   - Employed a patch-based discriminator to provide fine-grained expertise measurements and improve the stability and interpretability of visual imitation learning.\n   - Showed that PatchAIL outperforms baseline methods on standard benchmarks, providing valuable insights into visual demonstrations.\n\nOverall, the author's research significantly advances the fields of robotic simulation, multi-modal learning, and reinforcement learning, with a particular emphasis on creating more realistic, scalable, and generalizable robotic systems.",
    "list_of_pubs": [
      {
        "title": "Re$^3$Sim: Generating High-Fidelity Simulation Data via 3D-Photorealistic Real-to-Sim for Robotic Manipulation",
        "abstract": "Real-world data collection for robotics is costly and resource-intensive, requiring skilled operators and expensive hardware. Simulations offer a scalable alternative but often fail to achieve sim-to-real generalization due to geometric and visual gaps. To address these challenges, we propose a 3D-photorealistic real-to-sim system, namely, RE$^3$SIM, addressing geometric and visual sim-to-real gaps. RE$^3$SIM employs advanced 3D reconstruction and neural rendering techniques to faithfully recreate real-world scenarios, enabling real-time rendering of simulated cross-view cameras within a physics-based simulator. By utilizing privileged information to collect expert demonstrations efficiently in simulation, and train robot policies with imitation learning, we validate the effectiveness of the real-to-sim-to-real pipeline across various manipulation task scenarios. Notably, with only simulated data, we can achieve zero-shot sim-to-real transfer with an average success rate exceeding 58%. To push the limit of real-to-sim, we further generate a large-scale simulation dataset, demonstrating how a robust policy can be built from simulation data that generalizes across various objects. Codes and demos are available at: http://xshenhan.github.io/Re3Sim/."
      },
      {
        "title": "Towards Generalist Robot Policies: What Matters in Building Vision-Language-Action Models",
        "abstract": "Foundation Vision Language Models (VLMs) exhibit strong capabilities in multi-modal representation learning, comprehension, and reasoning. By injecting action components into the VLMs, Vision-Language-Action Models (VLAs) can be naturally formed and also show promising performance. Existing work has demonstrated the effectiveness and generalization of VLAs in multiple scenarios and tasks. Nevertheless, the transfer from VLMs to VLAs is not trivial since existing VLAs differ in their backbones, action-prediction formulations, data distributions, and training recipes. This leads to a missing piece for a systematic understanding of the design choices of VLAs. In this work, we disclose the key factors that significantly influence the performance of VLA and focus on answering three essential design choices: which backbone to select, how to formulate the VLA architectures, and when to add cross-embodiment data. The obtained results convince us firmly to explain why we need VLA and develop a new family of VLAs, RoboVLMs, which require very few manual designs and achieve a new state-of-the-art performance in three simulation tasks and real-world experiments. Through our extensive experiments, which include over 8 VLM backbones, 4 policy architectures, and over 600 distinct designed experiments, we provide a detailed guidebook for the future design of VLAs. In addition to the study, the highly flexible RoboVLMs framework, which supports easy integrations of new VLMs and free combinations of various design choices, is made public to facilitate future research. We open-source all details, including codes, models, datasets, and toolkits, along with detailed training and evaluation recipes at: robovlms.github.io."
      },
      {
        "title": "GenSim2: Scaling Robot Data Generation with Multi-modal and Reasoning LLMs",
        "abstract": "Robotic simulation today remains challenging to scale up due to the human efforts required to create diverse simulation tasks and scenes. Simulation-trained policies also face scalability issues as many sim-to-real methods focus on a single task. To address these challenges, this work proposes GenSim2, a scalable framework that leverages coding LLMs with multi-modal and reasoning capabilities for complex and realistic simulation task creation, including long-horizon tasks with articulated objects. To automatically generate demonstration data for these tasks at scale, we propose planning and RL solvers that generalize within object categories. The pipeline can generate data for up to 100 articulated tasks with 200 objects and reduce the required human efforts. To utilize such data, we propose an effective multi-task language-conditioned policy architecture, dubbed proprioceptive point-cloud transformer (PPT), that learns from the generated demonstrations and exhibits strong sim-to-real zero-shot transfer. Combining the proposed pipeline and the policy architecture, we show a promising usage of GenSim2 that the generated data can be used for zero-shot transfer or co-train with real-world collected data, which enhances the policy performance by 20% compared with training exclusively on limited real data."
      },
      {
        "title": "Long-Horizon Rollout via Dynamics Diffusion for Offline Reinforcement Learning",
        "abstract": "With the great success of diffusion models (DMs) in generating realistic synthetic vision data, many researchers have investigated their potential in decision-making and control. Most of these works utilized DMs to sample directly from the trajectory space, where DMs can be viewed as a combination of dynamics models and policies. In this work, we explore how to decouple DMs' ability as dynamics models in fully offline settings, allowing the learning policy to roll out trajectories. As DMs learn the data distribution from the dataset, their intrinsic policy is actually the behavior policy induced from the dataset, which results in a mismatch between the behavior policy and the learning policy. We propose Dynamics Diffusion, short as DyDiff, which can inject information from the learning policy to DMs iteratively. DyDiff ensures long-horizon rollout accuracy while maintaining policy consistency and can be easily deployed on model-free algorithms. We provide theoretical analysis to show the advantage of DMs on long-horizon rollout over models and demonstrate the effectiveness of DyDiff in the context of offline reinforcement learning, where the rollout dataset is provided but no online environment for interaction. Our code is at https://github.com/FineArtz/DyDiff."
      },
      {
        "title": "MADiff: Offline Multi-agent Learning with Diffusion Models",
        "abstract": "Offline reinforcement learning (RL) aims to learn policies from pre-existing datasets without further interactions, making it a challenging task. Q-learning algorithms struggle with extrapolation errors in offline settings, while supervised learning methods are constrained by model expressiveness. Recently, diffusion models (DMs) have shown promise in overcoming these limitations in single-agent learning, but their application in multi-agent scenarios remains unclear. Generating trajectories for each agent with independent DMs may impede coordination, while concatenating all agents\u2019 information can lead to low sample efficiency. Accordingly, we propose MADiff, which is realized with an attention-based diffusion model to model the complex coordination among behaviors of multiple agents. To our knowledge, MADiff is the first diffusion-based multi-agent learning framework, functioning as both a decentralized policy and a centralized controller. During decentralized executions, MADiff simultaneously performs teammate modeling, and the centralized controller can also be applied in multi-agent trajectory predictions. Our experiments demonstrate that MADiff outperforms baseline algorithms across various multi-agent learning tasks, highlighting its effectiveness in modeling complex multi-agent interactions."
      },
      {
        "title": "Visual Imitation Learning with Patch Rewards",
        "abstract": "Visual imitation learning enables reinforcement learning agents to learn to behave from expert visual demonstrations such as videos or image sequences, without explicit, well-defined rewards. Previous reseaches either adopt supervised learning techniques or induce simple and coarse scalar rewards from pixels, neglecting the dense information contained in the image demonstrations. In this work, we propose to measure the expertise of various local regions of image samples, or called patches, and recover multi-dimensional patch rewards accordingly. Patch reward is a more precise rewarding characterization that serves as fine-grained expertise measurement and visual explainability tool. Specifically, we present Adversarial Imitation Learning with Patch Rewards (PatchAIL), which employs a patch-based discriminator to measure the expertise of different local parts from given images and provide patch rewards. The patch-based knowledge is also used to regularize the aggregated reward and stabilize the training. We evaluate our method on the standard pixel-based benchmark DeepMind Control Suite. The experiment results have demonstrated that PatchAIL outperforms baseline methods and provides valuable interpretations for visual demonstrations."
      }
    ]
  },
  {
    "name": "Kounianhua Du",
    "publication_urls": [
      "https://arxiv.org/abs/2007.00216",
      "https://proceedings.neurips.cc/paper_files/paper/2022/hash/67e79c8e9b11f068a7cafd79505175c0-Abstract-Conference.html",
      "https://arxiv.org/abs/2308.11131"
    ],
    "summary": "The author's research contributions span several key areas within the field of machine learning and recommendation systems, particularly focusing on leveraging advanced models and techniques to enhance recommendation accuracy and efficiency. Here are the main contributions:\n\n1. **Neighborhood-based Interaction Model for Recommendation (NIRec)**:\n   - **Problem Addressed**: Existing HIN-based recommendation systems often struggle with sparse or noisy path connections and early summarization issues, which can lead to suboptimal performance.\n   - **Solution**: The author proposes NIRec, an end-to-end model that captures interactive patterns between nodes using metapath-guided neighborhoods. This approach uses convolutional operations and fast Fourier transform to efficiently model complex interactions, leading to significant performance gains over state-of-the-art methods on various heterogeneous graphs.\n\n2. **Learning Enhanced Representation for Tabular Data via Neighborhood Propagation (PET)**:\n   - **Problem Addressed**: Traditional methods for tabular data prediction often treat each data instance independently or fail to fully utilize multi-row features and labels to enhance target data representations.\n   - **Solution**: The author introduces PET, a model that constructs a hypergraph to model cross-row and cross-column patterns and performs message propagation to enhance target data instance representations. The model benefits from the fusion of labels and features during propagation and locality-aware multiplicative high-order interactions, demonstrating superior performance in tabular prediction tasks.\n\n3. **Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation (ReLLa)**:\n   - **Problem Addressed**: Large language models (LLMs) struggle with extracting useful information from long user behavior sequences, leading to poor performance in recommendation tasks.\n   - **Solution**: The author proposes ReLLa, a framework that enhances LLMs for zero-shot and few-shot recommendation tasks. For zero-shot recommendation, ReLLa uses semantic user behavior retrieval (SUBR) to improve data quality. For few-shot recommendation, it employs retrieval-enhanced instruction tuning (ReiT) to augment training samples. ReLLa demonstrates significant improvements over existing models, even with limited training data, and shows strong capabilities in lifelong sequential behavior comprehension.\n\nOverall, the author's research focuses on developing innovative models and techniques to address key challenges in recommendation systems, including handling complex graph structures, enhancing tabular data representations, and improving the performance of large language models in recommendation tasks. These contributions advance the state of the art in recommendation systems and provide practical solutions for real-world applications.",
    "list_of_pubs": [
      {
        "title": "An Efficient Neighborhood-based Interaction Model for Recommendation on Heterogeneous Graph",
        "abstract": "There is an influx of heterogeneous information network (HIN) based recommender systems in recent years since HIN is capable of characterizing complex graphs and contains rich semantics. Although the existing approaches have achieved performance improvement, while practical, they still face the following problems. On one hand, most existing HIN-based methods rely on explicit path reachability to leverage path-based semantic relatedness between users and items, e.g., metapath-based similarities. These methods are hard to use and integrate since path connections are sparse or noisy, and are often of different lengths. On the other hand, other graph-based methods aim to learn effective heterogeneous network representations by compressing node together with its neighborhood information into single embedding before prediction. This weakly coupled manner in modeling overlooks the rich interactions among nodes, which introduces an early summarization issue. In this paper, we propose an end-to-end Neighborhood-based Interaction Model for Recommendation (NIRec) to address the above problems. Specifically, we first analyze the significance of learning interactions in HINs and then propose a novel formulation to capture the interactive patterns between each pair of nodes through their metapath-guided neighborhoods. Then, to explore complex interactions between metapaths and deal with the learning complexity on large-scale networks, we formulate interaction in a convolutional way and learn efficiently with fast Fourier transform. The extensive experiments on four different types of heterogeneous graphs demonstrate the performance gains of NIRec comparing with state-of-the-arts. To the best of our knowledge, this is the first work providing an efficient neighborhood-based interaction model in the HIN-based recommendations."
      },
      {
        "title": "Learning Enhanced Representation for Tabular Data via Neighborhood Propagation",
        "abstract": "Prediction over tabular data is an essential and fundamental problem in many important downstream tasks. However, existing methods either take a data instance of the table independently as input or do not fully utilize the multi-row features and labels to directly change and enhance the target data representations. In this paper, we propose to 1) construct a hypergraph from relevant data instance retrieval to model the cross-row and cross-column patterns of those instances, and 2) perform message Propagation to Enhance the target data instance representation for Tabular prediction tasks. Specifically, our specially-designed message propagation step benefits from 1) the fusion of label and features during propagation, and 2) locality-aware multiplicative high-order interaction between features. Experiments on two important tabular prediction tasks validate the superiority of the proposed PET model against other baselines. Additionally, we demonstrate the effectiveness of the model components and the feature enhancement ability of PET via various ablation studies and visualizations. The code is available at https://github.com/KounianhuaDu/PET."
      },
      {
        "title": "ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation",
        "abstract": "With large language models (LLMs) achieving remarkable breakthroughs in natural language processing (NLP) domains, LLM-enhanced recommender systems have received much attention and have been actively explored currently. In this paper, we focus on adapting and empowering a pure large language model for zero-shot and few-shot recommendation tasks. First and foremost, we identify and formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation domains, i.e., LLMs fail to extract useful information from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs. To address such an issue and improve the recommendation performance of LLMs, we propose a novel framework, namely Retrieval-enhanced Large Language models (ReLLa) for recommendation tasks in both zero-shot and few-shot settings. For zero-shot recommendation, we perform semantic user behavior retrieval (SUBR) to improve the data quality of testing samples, which greatly reduces the difficulty for LLMs to extract the essential knowledge from user behavior sequences. As for few-shot recommendation, we further design retrieval-enhanced instruction tuning (ReiT) by adopting SUBR as a data augmentation technique for training samples. Specifically, we develop a mixed training dataset consisting of both the original data samples and their retrieval-enhanced counterparts. We conduct extensive experiments on three real-world public datasets to demonstrate the superiority of ReLLa compared with existing baseline models, as well as its capability for lifelong sequential behavior comprehension. To be highlighted, with only less than 10% training samples, few-shot ReLLa can outperform traditional CTR models that are trained on the entire training set (e.g., DCNv2, DIN, SIM). The code is available \\url{https://github.com/LaVieEnRose365/ReLLa}."
      }
    ]
  },
  {
    "name": "Liangming Pan",
    "publication_urls": [
      "https://arxiv.org/abs/2502.15823",
      "https://arxiv.org/abs/2402.11451",
      "https://arxiv.org/abs/2410.08414",
      "https://arxiv.org/abs/2406.19215"
    ],
    "summary": "The author's research contributions primarily revolve around enhancing and evaluating the capabilities of large language models (LLMs) in various reasoning tasks, particularly focusing on inductive reasoning, scientific reasoning, the integration of parametric and contextual knowledge, and adaptive retrieval-augmented generation. Here are the key contributions:\n\n1. **InductionBench**:\n   - **Contribution**: Developed a benchmark to evaluate the inductive reasoning capabilities of LLMs.\n   - **Impact**: Revealed that even advanced LLMs struggle with inductive reasoning tasks, especially those involving the simplest complexity classes within the subregular hierarchy of functions. This highlights a significant gap in the current capabilities of LLMs.\n\n2. **SciAgent**:\n   - **Contribution**: Introduced a tool-augmented setting for scientific reasoning, where LLMs are supplemented with scalable toolsets to enhance their problem-solving abilities.\n   - **Impact**: Constructed a training corpus (MathFunc) and a benchmark (SciToolBench) to evaluate LLMs with tool assistance. The developed SciAgent significantly outperformed other LLMs in scientific reasoning tasks, demonstrating the effectiveness of tool-augmented approaches.\n\n3. **Understanding the Interplay between Parametric and Contextual Knowledge**:\n   - **Contribution**: Investigated how LLMs integrate their internal parametric knowledge (PK) with external contextual knowledge (CK).\n   - **Impact**: Identified four types of interactions between PK and CK (Supportive, Complementary, Conflicting, and Irrelevant) and found that LLMs often suppress their PK when CK is available, even if it is complementary or irrelevant. This highlights a critical vulnerability in LLMs, particularly in knowledge-intensive tasks.\n\n4. **SeaKR (Self-aware Knowledge Retrieval)**:\n   - **Contribution**: Developed an adaptive retrieval-augmented generation (RAG) model that uses LLMs' self-aware uncertainty to decide when and how to retrieve and integrate external knowledge.\n   - **Impact**: Showed that SeaKR outperforms existing adaptive RAG methods on both complex and simple question-answering datasets. The model's ability to adaptively choose reasoning strategies based on its self-aware uncertainty enhances its performance in knowledge-intensive tasks.\n\nOverall, the author's work contributes to advancing the understanding and capabilities of LLMs in reasoning tasks, particularly by addressing gaps in inductive reasoning, enhancing scientific reasoning through tool augmentation, investigating the interplay between internal and external knowledge, and developing adaptive retrieval mechanisms. These contributions are crucial for improving the reliability and effectiveness of LLMs in real-world applications.",
    "list_of_pubs": [
      {
        "title": "InductionBench: LLMs Fail in the Simplest Complexity Class",
        "abstract": "Large language models (LLMs) have shown remarkable improvements in reasoning and many existing benchmarks have been addressed by models such as o1 and o3 either fully or partially. However, a majority of these benchmarks emphasize deductive reasoning, including mathematical and coding tasks in which rules such as mathematical axioms or programming syntax are clearly defined, based on which LLMs can plan and apply these rules to arrive at a solution. In contrast, inductive reasoning, where one infers the underlying rules from observed data, remains less explored. Such inductive processes lie at the heart of scientific discovery, as they enable researchers to extract general principles from empirical observations. To assess whether LLMs possess this capacity, we introduce InductionBench, a new benchmark designed to evaluate the inductive reasoning ability of LLMs. Our experimental findings reveal that even the most advanced models available struggle to master the simplest complexity classes within the subregular hierarchy of functions, highlighting a notable deficiency in current LLMs' inductive reasoning capabilities. Coda and data are available https://github.com/Wenyueh/inductive_reasoning_benchmark."
      },
      {
        "title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
        "abstract": "Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools. Building on MathFunc, we develop SciAgent to retrieve, understand and, if necessary, use tools for scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs' abilities with tool assistance. Extensive experiments on SciToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Mistral-7B surpasses other LLMs with the same size by more than 13% in absolute accuracy. Furthermore, SciAgent-DeepMath-7B shows much superior performance than ChatGPT."
      },
      {
        "title": "Understanding the Interplay between Parametric and Contextual Knowledge for Large Language Models",
        "abstract": "Large language models (LLMs) encode vast amounts of knowledge during pre-training (parametric knowledge, or PK) and can further be enhanced by incorporating contextual knowledge (CK). Can LLMs effectively integrate their internal PK with external CK to solve complex problems? In this paper, we investigate the dynamic interaction between PK and CK, categorizing their relationships into four types: Supportive, Complementary, Conflicting, and Irrelevant. To support this investigation, we introduce ECHOQA, a benchmark spanning scientific, factual, and commonsense knowledge. Our results show that LLMs tend to suppress their PK when contextual information is available, even when it is complementary or irrelevant. While tailored instructions can encourage LLMs to rely more on their PK, they still struggle to fully leverage it. These findings reveal a key vulnerability in LLMs, raising concerns about their reliability in knowledge-intensive tasks. Resources are available at https://github.com/sitaocheng/Knowledge_Interplay"
      },
      {
        "title": "SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation",
        "abstract": "This paper introduces Self-aware Knowledge Retrieval (SeaKR), a novel adaptive RAG model that extracts self-aware uncertainty of LLMs from their internal states. SeaKR activates retrieval when the LLMs present high self-aware uncertainty for generation. To effectively integrate retrieved knowledge snippets, SeaKR re-ranks them based on LLM's self-aware uncertainty to preserve the snippet that reduces their uncertainty to the utmost. To facilitate solving complex tasks that require multiple retrievals, SeaKR utilizes their self-aware uncertainty to choose among different reasoning strategies. Our experiments on both complex and simple Question Answering datasets show that SeaKR outperforms existing adaptive RAG methods. We release our code at https://github.com/THU-KEG/SeaKR."
      }
    ]
  },
  {
    "name": "Kan Ren",
    "publication_urls": [
      "https://arxiv.org/abs/1611.00144",
      "https://arxiv.org/abs/2503.09046",
      "https://proceedings.neurips.cc/paper_files/paper/2024/hash/84bad835faaf48f24d990072bb5b80ee-Abstract-Conference.html",
      "https://arxiv.org/abs/2403.12641",
      "https://arxiv.org/abs/2403.11960",
      "https://arxiv.org/abs/2405.16173"
    ],
    "summary": "The author's research spans multiple domains within machine learning and artificial intelligence, with a focus on developing innovative methodologies and frameworks to address complex problems in user response prediction, deep learning interpretability, brain-computer interfaces, automated machine learning, spatiotemporal data processing, and reinforcement learning. Here is a summary of the main contributions:\n\n1. **User Response Prediction**:\n   - Developed **Product-based Neural Networks (PNN)**, a novel architecture that combines an embedding layer, a product layer, and fully connected layers to effectively capture both low-order and high-order feature interactions in high-dimensional sparse data.\n   - Demonstrated superior performance of PNNs compared to state-of-the-art models on large-scale real-world ad click datasets, highlighting its ability to handle categorical data and predict user responses accurately.\n\n2. **Deep Learning Interpretability**:\n   - Investigated the **influential neuron paths** in Vision Transformers, proposing a joint influence measure and a layer-progressive neuron locating approach to identify the most significant paths from input to output.\n   - Showed that the identified neuron paths preserve the model's capability on downstream tasks and provided insights into the inner workings of Vision Transformers, contributing to the transparency and trustworthiness of these models.\n\n3. **Brain-Computer Interfaces**:\n   - Introduced **EEG2Video**, a framework for decoding dynamic visual perception from EEG signals, addressing the gap in existing literature that primarily focuses on static visual stimuli.\n   - Created a large dataset of EEG-video pairs and proposed a Seq2Seq architecture for video reconstruction, achieving high accuracy in semantic classification and structural similarity.\n\n4. **Automated Machine Learning**:\n   - Developed **Automated Contrastive Learning (AutoCL)**, an AutoML approach for automatically learning contrastive learning strategies (CLS) for time series datasets.\n   - Constructed a large search space and used reinforcement learning to optimize CLS, demonstrating the effectiveness of AutoCL on various real-world datasets and composing a transferable Generally Good Strategy (GGS).\n\n5. **Spatiotemporal Data Processing**:\n   - Proposed **Causality-Aware Spatiotemporal Graph Neural Networks (Casper)** for spatiotemporal time series imputation, incorporating causal relationships to reduce the impact of confounders and improve imputation accuracy.\n   - Introduced a Prompt Based Decoder (PBD) and Spatiotemporal Causal Attention (SCA) to discover sparse causal relationships, showing superior performance on real-world datasets.\n\n6. **Reinforcement Learning**:\n   - Developed **Q-weighted Variational Policy Optimization (QVPO)**, a novel model-free diffusion-based online RL algorithm that addresses the limitations of existing diffusion policies in online settings.\n   - Designed a Q-weighted variational loss and special entropy regularization to enhance exploration and prevent convergence to sub-optimal policies, achieving state-of-the-art performance on MuJoCo benchmarks in terms of cumulative reward and sample efficiency.\n\nOverall, the author's work is characterized by a strong emphasis on practical applications, theoretical rigor, and innovative methodologies that push the boundaries of current techniques in machine learning and AI.",
    "list_of_pubs": [
      {
        "title": "Product-based Neural Networks for User Response Prediction",
        "abstract": "Predicting user responses, such as clicks and conversions, is of great importance and has found its usage in many Web applications including recommender systems, web search and online advertising. The data in those applications is mostly categorical and contains multiple fields; a typical representation is to transform it into a high-dimensional sparse binary feature representation via one-hot encoding. Facing with the extreme sparsity, traditional models may limit their capacity of mining shallow patterns from the data, i.e. low-order feature combinations. Deep models like deep neural networks, on the other hand, cannot be directly applied for the high-dimensional input because of the huge feature space. In this paper, we propose a Product-based Neural Networks (PNN) with an embedding layer to learn a distributed representation of the categorical data, a product layer to capture interactive patterns between inter-field categories, and further fully connected layers to explore high-order feature interactions. Our experimental results on two large-scale real-world ad click datasets demonstrate that PNNs consistently outperform the state-of-the-art models on various metrics."
      },
      {
        "title": "Discovering Influential Neuron Path in Vision Transformers",
        "abstract": "Vision Transformer models exhibit immense power yet remain opaque to human understanding, posing challenges and risks for practical applications. While prior research has attempted to demystify these models through input attribution and neuron role analysis, there's been a notable gap in considering layer-level information and the holistic path of information flow across layers. In this paper, we investigate the significance of influential neuron paths within vision Transformers, which is a path of neurons from the model input to output that impacts the model inference most significantly. We first propose a joint influence measure to assess the contribution of a set of neurons to the model outcome. And we further provide a layer-progressive neuron locating approach that efficiently selects the most influential neuron at each layer trying to discover the crucial neuron path from input to output within the target model. Our experiments demonstrate the superiority of our method finding the most influential neuron path along which the information flows, over the existing baseline solutions. Additionally, the neuron paths have illustrated that vision Transformers exhibit some specific inner working mechanism for processing the visual information within the same image category. We further analyze the key effects of these neurons on the image classification task, showcasing that the found neuron paths have already preserved the model capability on downstream tasks, which may also shed some lights on real-world applications like model pruning. The project website including implementation code is available at https://foundation-model-research.github.io/NeuronPath/."
      },
      {
        "title": "EEG2Video: Towards Decoding Dynamic Visual Perception from EEG Signals",
        "abstract": "Our visual experience in daily life are dominated by dynamic change. Decoding such dynamic information from brain activity can enhance the understanding of the brain\u2019s visual processing system. However, previous studies predominately focus on reconstructing static visual stimuli. In this paper, we explore to decode dynamic visual perception from electroencephalography (EEG), a neuroimaging technique able to record brain activity with high temporal resolution (1000 Hz) for capturing rapid changes in brains. Our contributions are threefold: Firstly, we develop a large dataset recording signals from 20 subjects while they were watching 1400 dynamic video clips of 40 concepts. This dataset fills the gap in the lack of EEG-video pairs. Secondly, we annotate each video clips to investigate the potential for decoding some specific meta information (e.g., color, dynamic, human or not) from EEG. Thirdly, we propose a novel baseline EEG2Video for video reconstruction from EEG signals that better aligns dynamic movements with high temporal resolution brain signals by Seq2Seq architecture. EEG2Video achieves a 2-way accuracy of 79.8% in semantic classification tasks and 0.256 in structural similarity index (SSIM). Overall, our works takes an important step towards decoding dynamic visual perception from EEG signals. Our dataset and code will be released soon."
      },
      {
        "title": "Automated Contrastive Learning Strategy Search for Time Series",
        "abstract": "In recent years, Contrastive Learning (CL) has become a predominant representation learning paradigm for time series. Most existing methods manually build specific CL Strategies (CLS) by human heuristics for certain datasets and tasks. However, manually developing CLS usually requires excessive prior knowledge about the data, and massive experiments to determine the detailed CL configurations. In this paper, we present an Automated Machine Learning (AutoML) practice at Microsoft, which automatically learns CLS for time series datasets and tasks, namely Automated Contrastive Learning (AutoCL). We first construct a principled search space of size over $3\\times10^{12}$, covering data augmentation, embedding transformation, contrastive pair construction, and contrastive losses. Further, we introduce an efficient reinforcement learning algorithm, which optimizes CLS from the performance on the validation tasks, to obtain effective CLS within the space. Experimental results on various real-world datasets demonstrate that AutoCL could automatically find the suitable CLS for the given dataset and task. From the candidate CLS found by AutoCL on several public datasets/tasks, we compose a transferable Generally Good Strategy (GGS), which has a strong performance for other datasets. We also provide empirical analysis as a guide for the future design of CLS."
      },
      {
        "title": "Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation",
        "abstract": "Spatiotemporal time series are usually collected via monitoring sensors placed at different locations, which usually contain missing values due to various failures, such as mechanical damages and Internet outages. Imputing the missing values is crucial for analyzing time series. When recovering a specific data point, most existing methods consider all the information relevant to that point regardless of the cause-and-effect relationship. During data collection, it is inevitable that some unknown confounders are included, e.g., background noise in time series and non-causal shortcut edges in the constructed sensor network. These confounders could open backdoor paths and establish non-causal correlations between the input and output. Over-exploiting these non-causal correlations could cause overfitting. In this paper, we first revisit spatiotemporal time series imputation from a causal perspective and show how to block the confounders via the frontdoor adjustment. Based on the results of frontdoor adjustment, we introduce a novel Causality-Aware Spatiotemporal Graph Neural Network (Casper), which contains a novel Prompt Based Decoder (PBD) and a Spatiotemporal Causal Attention (SCA). PBD could reduce the impact of confounders and SCA could discover the sparse causal relationships among embeddings. Theoretical analysis reveals that SCA discovers causal relationships based on the values of gradients. We evaluate Casper on three real-world datasets, and the experimental results show that Casper could outperform the baselines and could effectively discover causal relationships."
      },
      {
        "title": "Diffusion-based Reinforcement Learning via Q-weighted Variational Policy Optimization",
        "abstract": "Diffusion models have garnered widespread attention in Reinforcement Learning (RL) for their powerful expressiveness and multimodality. It has been verified that utilizing diffusion policies can significantly improve the performance of RL algorithms in continuous control tasks by overcoming the limitations of unimodal policies, such as Gaussian policies, and providing the agent with enhanced exploration capabilities. However, existing works mainly focus on the application of diffusion policies in offline RL, while their incorporation into online RL is less investigated. The training objective of the diffusion model, known as the variational lower bound, cannot be optimized directly in online RL due to the unavailability of 'good' actions. This leads to difficulties in conducting diffusion policy improvement. To overcome this, we propose a novel model-free diffusion-based online RL algorithm, Q-weighted Variational Policy Optimization (QVPO). Specifically, we introduce the Q-weighted variational loss, which can be proved to be a tight lower bound of the policy objective in online RL under certain conditions. To fulfill these conditions, the Q-weight transformation functions are introduced for general scenarios. Additionally, to further enhance the exploration capability of the diffusion policy, we design a special entropy regularization term. We also develop an efficient behavior policy to enhance sample efficiency by reducing the variance of the diffusion policy during online interactions. Consequently, the QVPO algorithm leverages the exploration capabilities and multimodality of diffusion policies, preventing the RL agent from converging to a sub-optimal policy. To verify the effectiveness of QVPO, we conduct comprehensive experiments on MuJoCo benchmarks. The final results demonstrate that QVPO achieves state-of-the-art performance on both cumulative reward and sample efficiency."
      }
    ]
  }
]